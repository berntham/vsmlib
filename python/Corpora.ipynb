{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.corpus.gutenberg.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "['austen-emma.txt',\n",
        " 'austen-persuasion.txt',\n",
        " 'austen-sense.txt',\n",
        " 'bible-kjv.txt',\n",
        " 'blake-poems.txt',\n",
        " 'bryant-stories.txt',\n",
        " 'burgess-busterbrown.txt',\n",
        " 'carroll-alice.txt',\n",
        " 'chesterton-ball.txt',\n",
        " 'chesterton-brown.txt',\n",
        " 'chesterton-thursday.txt',\n",
        " 'edgeworth-parents.txt',\n",
        " 'melville-moby_dick.txt',\n",
        " 'milton-paradise.txt',\n",
        " 'shakespeare-caesar.txt',\n",
        " 'shakespeare-hamlet.txt',\n",
        " 'shakespeare-macbeth.txt',\n",
        " 'whitman-leaves.txt']"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#emma=nltk.corpus.gutenberg.words('austen-emma.txt')\n",
      "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
      "len(emma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "192427"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import gutenberg\n",
      "for fileid in gutenberg.fileids():\n",
      "    num_chars = len(gutenberg.raw(fileid))\n",
      "    num_words = len(gutenberg.words(fileid))\n",
      "    num_sents = len(gutenberg.sents(fileid))\n",
      "    num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))\n",
      "    print (int(num_chars/num_words), int(num_words/num_sents), int(num_words/num_vocab), fileid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4 24 26 austen-emma.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26 16 austen-persuasion.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28 22 austen-sense.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33 79 bible-kjv.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19 5 blake-poems.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19 14 bryant-stories.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17 12 burgess-busterbrown.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20 12 carroll-alice.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20 11 chesterton-ball.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22 11 chesterton-brown.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18 10 chesterton-thursday.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20 24 edgeworth-parents.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25 15 melville-moby_dick.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 52 10 milton-paradise.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11 8 shakespeare-caesar.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12 7 shakespeare-hamlet.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12 6 shakespeare-macbeth.txt\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36 12 whitman-leaves.txt\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "brown.categories()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "['adventure',\n",
        " 'belles_lettres',\n",
        " 'editorial',\n",
        " 'fiction',\n",
        " 'government',\n",
        " 'hobbies',\n",
        " 'humor',\n",
        " 'learned',\n",
        " 'lore',\n",
        " 'mystery',\n",
        " 'news',\n",
        " 'religion',\n",
        " 'reviews',\n",
        " 'romance',\n",
        " 'science_fiction']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_text = brown.words(categories='news')\n",
      "fdist = nltk.FreqDist([w.lower() for w in news_text])\n",
      "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
      "for m in modals:\n",
      "    print (m + ':', fdist[m],)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "can: 94\n",
        "could: 87\n",
        "may: 93\n",
        "might: 38\n",
        "must: 53\n",
        "will: 389\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cfd = nltk.ConditionalFreqDist(\n",
      "(genre, word)\n",
      "for genre in brown.categories()\n",
      "for word in brown.words(categories=genre))\n",
      "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
      "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
      "cfd.tabulate(conditions=genres, samples=modals)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                 can could  may might must will \n",
        "           news   93   86   66   38   50  389 \n",
        "       religion   82   59   78   12   54   71 \n",
        "        hobbies  268   58  131   22   83  264 \n",
        "science_fiction   16   49    4   12    8   16 \n",
        "        romance   74  193   11   51   45   43 \n",
        "          humor   16   30    8    8    9   13 \n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import inaugural\n",
      "cfd = nltk.ConditionalFreqDist(\n",
      "(target, fileid[:4])\n",
      "for fileid in inaugural.fileids()\n",
      "for w in inaugural.words(fileid)\n",
      "for target in ['america', 'citizen']\n",
      "if w.lower().startswith(target))\n",
      "cfd.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import PlaintextCorpusReader\n",
      "corpus_root = 'corpus'\n",
      "wordlists = PlaintextCorpusReader(corpus_root, '.*')\n",
      "wordlists.fileids()\n",
      "#wordlists.words('clarissa1.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "['clarissa1.txt']"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genre_word = [(genre, word) for genre in ['news', 'romance'] for word in brown.words(categories=genre)]\n",
      "#genre_word[:10]\n",
      "cfd = nltk.ConditionalFreqDist(genre_word)\n",
      "cfd.conditions()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['romance', 'news']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import inaugural\n",
      "cfd = nltk.ConditionalFreqDist(\n",
      "(target, fileid[:4])\n",
      "for fileid in inaugural.fileids()\n",
      "for w in inaugural.words(fileid)\n",
      "for target in ['america', 'citizen']\n",
      "if w.lower().startswith(target))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "stopwords.words('english')[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import wordnet as wn\n",
      "wn.synsets('motorcar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[Synset('car.n.01')]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').lemma_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "['car', 'auto', 'automobile', 'machine', 'motorcar']"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').definition()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wn.synset('car.n.01').examples()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "['he needs a car to get to work']"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = brown.sents()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "57340"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('brown.txt', 'w')\n",
      "for s in t:\n",
      "    for w in s:\n",
      "        if not w in stopwords.words('english') and len(w)>1:\n",
      "            f.write(w.lower()+\" \")\n",
      "    f.write(\"\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}