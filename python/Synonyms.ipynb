{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.collocations import *\n",
      "from nltk.corpus import stopwords\n",
      "import numpy\n",
      "import matplotlib\n",
      "import inspect"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import brown\n",
      "len(brown.words())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "1161192"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#mytext=nltk.Text(brown.words())\n",
      "text = \"I do not like green eggs and ham, I do not like them Sam I am!\"\n",
      "tokens = nltk.wordpunct_tokenize(text)\n",
      "list(nltk.bigrams(tokens))\n",
      "#finder = BigramCollocationFinder.from_words(tokens,3)\n",
      "#finder = BigramCollocationFinder.from_documents(brown)\n",
      "#scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
      "#sorted(bigram for bigram, score in scored)[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "[('I', 'do'),\n",
        " ('do', 'not'),\n",
        " ('not', 'like'),\n",
        " ('like', 'green'),\n",
        " ('green', 'eggs'),\n",
        " ('eggs', 'and'),\n",
        " ('and', 'ham'),\n",
        " ('ham', ','),\n",
        " (',', 'I'),\n",
        " ('I', 'do'),\n",
        " ('do', 'not'),\n",
        " ('not', 'like'),\n",
        " ('like', 'them'),\n",
        " ('them', 'Sam'),\n",
        " ('Sam', 'I'),\n",
        " ('I', 'am'),\n",
        " ('am', '!')]"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bigrams_by_word(text,w,window_size=2):\n",
      "    finder = BigramCollocationFinder.from_words(text,window_size)\n",
      "    #finder = BigramCollocationFinder.from_words(self.tokens, window_size)\n",
      "    finder.apply_freq_filter(2)\n",
      "    ignored_words = stopwords.words('english')\n",
      "    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
      "    myfilter = lambda *w1: w not in w1\n",
      "    finder.apply_ngram_filter(myfilter)\n",
      "    #collocations = finder.nbest(bigram_measures.likelihood_ratio, num)\\n',\n",
      "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
      "    scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
      "    #scored = finder.score_ngrams(bigram_measures.pmi)\n",
      "    #scored = finder.score_ngrams(bigram_measures.likelihood_ratio)\n",
      "    return scored[:20]\n",
      "    \n",
      "\n",
      "#sorted(scored)[:10]\n",
      "#sorted((bigram for bigram, score in scored),10) \n",
      "#finder.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = nltk.corpus.brown.words()\n",
      "ignored_words = stopwords.words('english')\n",
      "text= [w.lower() for w in words if len(w) > 3 and not w.lower() in ignored_words]\n",
      "bigrams = nltk.bigrams(text)\n",
      "cfd = nltk.ConditionalFreqDist(bigrams)\n",
      "print(cfd[\"fast\"])\n",
      "print(cfd[\"quick\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FreqDist({'ball': 2, 'pace': 2, 'moving': 2, 'possibly': 1, 'sent': 1, 'people': 1, 'knew': 1, 'footwork': 1, \"let's\": 1, 'drastic': 1, ...})\n",
        "FreqDist({'succession': 2, 'accurate': 2, 'glance': 2, 'study': 1, 'firm': 1, 'pack': 1, 'lecture': 1, 'strides': 1, 'replied': 1, 'free': 1, ...})\n"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_bigrams_by_word(text,\"fast\",window_size=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 220,
       "text": [
        "[(('even', 'fast'), 3.027795159564805e-06),\n",
        " (('could', 'fast'), 3.027795159564805e-06),\n",
        " (('fast', 'ball'), 2.0185301063765366e-06),\n",
        " (('fast', 'action'), 2.0185301063765366e-06),\n",
        " (('would', 'fast'), 2.0185301063765366e-06),\n",
        " (('fast', 'pace'), 2.0185301063765366e-06),\n",
        " (('fast', 'nothing'), 2.0185301063765366e-06),\n",
        " (('fast', 'time'), 2.0185301063765366e-06),\n",
        " (('move', 'fast'), 2.0185301063765366e-06),\n",
        " (('fast', 'could'), 2.0185301063765366e-06),\n",
        " (('combine', 'fast'), 2.0185301063765366e-06),\n",
        " (('fast', 'muscle'), 2.0185301063765366e-06),\n",
        " (('patrol', 'fast'), 2.0185301063765366e-06),\n",
        " (('fast', 'took'), 2.0185301063765366e-06),\n",
        " (('came', 'fast'), 2.0185301063765366e-06),\n",
        " (('fast', 'moving'), 2.0185301063765366e-06),\n",
        " (('thing', 'fast'), 2.0185301063765366e-06)]"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_bigrams_by_word(text,\"quick\",window_size=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 221,
       "text": [
        "[(('gave', 'quick'), 4.037060212753073e-06),\n",
        " (('back', 'quick'), 3.027795159564805e-06),\n",
        " (('give', 'quick'), 2.0185301063765366e-06),\n",
        " (('never', 'quick'), 2.0185301063765366e-06),\n",
        " (('quick', 'glance'), 2.0185301063765366e-06),\n",
        " (('quick', 'look'), 2.0185301063765366e-06),\n",
        " (('make', 'quick'), 2.0185301063765366e-06),\n",
        " (('pretty', 'quick'), 2.0185301063765366e-06),\n",
        " (('capitalism', 'quick'), 2.0185301063765366e-06),\n",
        " (('quick', 'succession'), 2.0185301063765366e-06),\n",
        " (('quick', 'shrank'), 2.0185301063765366e-06),\n",
        " (('came', 'quick'), 2.0185301063765366e-06),\n",
        " (('quick', 'accurate'), 2.0185301063765366e-06),\n",
        " (('quick', 'could'), 2.0185301063765366e-06)]"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#load BNC\n",
      "import fnmatch\n",
      "import os\n",
      "\n",
      "matches = []\n",
      "dir_root='/mnt/storage/Corpora/BNC/B/'\n",
      "for root, dirnames, filenames in os.walk(dir_root):\n",
      "  for filename in fnmatch.filter(filenames, '*.xml'):\n",
      "      matches.append(os.path.join(root, filename)[len(dir_root):])\n",
      "#matches\n",
      "bnc=nltk.corpus.reader.bnc.BNCCorpusReader(dir_root,matches)\n",
      "len(bnc.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 241,
       "text": [
        "7475429"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#text2.collocations()\n",
      "mytext=nltk.Text(bnc.words())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_bigrams_by_word(mytext,\"skinny\",window_size=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 243,
       "text": [
        "[(('tall', 'skinny'), 1.3377158688819062e-07),\n",
        " (('skinny', 'legs'), 1.3377158688819062e-07),\n",
        " (('skinny', 'frame'), 1.3377158688819062e-07),\n",
        " (('laying', 'skinny'), 8.918105792546042e-08),\n",
        " (('skinny', 'finger'), 8.918105792546042e-08),\n",
        " (('Upon', 'skinny'), 8.918105792546042e-08),\n",
        " (('skinny', 'little'), 8.918105792546042e-08),\n",
        " (('skinny', 'lips'), 8.918105792546042e-08),\n",
        " (('skinny', 'Rab'), 8.918105792546042e-08)]"
       ]
      }
     ],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_bigrams_by_word(mytext,\"thin\",window_size=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 244,
       "text": [
        "[(('thin', 'man'), 2.9429749115401937e-06),\n",
        " (('long', 'thin'), 7.134484634036834e-07),\n",
        " (('tall', 'thin'), 6.24267405478223e-07),\n",
        " (('said', 'thin'), 5.350863475527625e-07),\n",
        " (('thin', 'ground'), 4.013147606645719e-07),\n",
        " (('thin', 'face'), 3.567242317018417e-07),\n",
        " (('thin', 'layers'), 2.6754317377638124e-07),\n",
        " (('thin', 'sheets'), 2.6754317377638124e-07),\n",
        " (('Michael', 'thin'), 2.6754317377638124e-07),\n",
        " (('thin', 'layer'), 2.6754317377638124e-07),\n",
        " (('thin', 'air'), 2.6754317377638124e-07),\n",
        " (('thin', 'steel'), 2.2295264481365106e-07),\n",
        " (('thin', 'bone'), 2.2295264481365106e-07),\n",
        " (('wafer', 'thin'), 2.2295264481365106e-07),\n",
        " (('thin', 'films'), 2.2295264481365106e-07),\n",
        " (('thin', 'lines'), 2.2295264481365106e-07),\n",
        " (('Leader', 'thin'), 1.7836211585092084e-07),\n",
        " (('thin', 'line'), 1.7836211585092084e-07),\n",
        " (('thin', 'coals'), 1.7836211585092084e-07),\n",
        " (('thin', 'said'), 1.7836211585092084e-07)]"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_bigrams_by_word(mytext,\"rapid\",window_size=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 236,
       "text": [
        "[(('rapid', 'progress'), 1.0288648020206905e-06),\n",
        " (('rapid', 'expansion'), 1.0288648020206905e-06),\n",
        " (('made', 'rapid'), 1.0288648020206905e-06),\n",
        " (('rapid', 'growth'), 6.859098680137936e-07),\n",
        " (('rapid', 'scan'), 6.859098680137936e-07),\n",
        " (('rapid', 'NMR'), 6.859098680137936e-07)]"
       ]
      }
     ],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(bnc.words()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}